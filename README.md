# Eye Disease Classifier

A PyTorch-based deep learning project for automatic classification of ocular diseases from retinal fundus images. This project explores multiple CNN architectures and transfer learning approaches for binary disease risk classification and multi label classification.

## ğŸ¯ Project Goal

This is a learning-focused project designed to:
- Master **PyTorch** for computer vision and image classification
- Explore and compare multiple model architectures (Simple CNN, DenseNet121, ResNet50)
- Implement transfer learning and fine-tuning techniques
- Build a strong portfolio project for roles in ML/AI and bioinformatics
- Implement and train Vision Transformer models for medical image classification

## ğŸ“Š Dataset

This project uses the **RFMiD (Retinal Fundus Multi-disease Image Dataset)**:
- **3,200** color fundus images
- Captured using **3 different fundus cameras**
- **46 conditions** annotated with consensus from senior retinal experts
- **License**: CC-BY 4.0
- **Source**: https://www.mdpi.com/2306-5729/6/2/14 ; https://riadd.grand-challenge.org/download-all-classes/ 

### Diseases Targeted
Currently developing a **binary classification model** to predict disease risk presence:
- **DR** (Diabetic Retinopathy)
- **MH** (Media Haze)
- **ODC** (Optic Disc Cupping)

## ğŸ› ï¸ Models & Architectures

The project includes implementations of multiple approaches:

| Model | Type | Status |
|-------|------|--------|
| Simple CNN | Custom CNN | Trained |
| ResNet50 | Transfer Learning (Fine-tuned) | Trained |
| DenseNet121 | Transfer Learning (Fine-tuned) | Trained |
| Vision Transformer | ViT-based classifier | Trained |
| Swin Transformer | Fine-tuned Swin-T | Trained |

## ğŸš€ Getting Started

### Prerequisites
- Python 3.13
- GPU with CUDA support (tested on RTX 5070 Ti)
- At least 16GB RAM for model training

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd Eye-Disease-Classifier
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install --upgrade pip setuptools wheel
pip install numpy pillow matplotlib pandas tqdm
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130
pip install torchmetrics torchinfo
```

### Download Dataset
- Download RFMiD dataset from: https://riadd.grand-challenge.org/download-all-classes/
- Extract to the `data/source/` directory

## ğŸ“ Project Structure

```
â”œâ”€â”€ classes/                          # Model definitions
â”‚   â”œâ”€â”€ ViT.py                        # Vision Transformer implementation
â”‚   â”œâ”€â”€ RetinaSimpleCNN.py            # Custom CNN architecture
â”‚   â”œâ”€â”€ CNNBinaryClassif.py           # Binary classification wrapper
â”‚   â”œâ”€â”€ CNNMultiClassMultiLabeling.py # Multi-label approach
â”‚   â””â”€â”€ RetinaDataset.py              # PyTorch Dataset class
â”‚
â”œâ”€â”€ model-training/                   # Training pipelines
â”‚   â”œâ”€â”€ Training-Notebooks/           # Jupyter notebooks for training
â”‚   â”‚   â”œâ”€â”€ Simple_CNN_BC.ipynb
â”‚   â”‚   â”œâ”€â”€ Simple_CNN_MCMLC.ipynb
â”‚   â”‚   â”œâ”€â”€ FT_ResNet50_BC.ipynb
â”‚   â”‚   â”œâ”€â”€ FT_ResNet50_MCMLC.ipynb
â”‚   â”‚   â”œâ”€â”€ FT_DenseNet121_BC.ipynb
â”‚   â”‚   â”œâ”€â”€ FT_DenseNet121_MCMLC.ipynb
â”‚   â”‚   â”œâ”€â”€ FT_swin_t_BC.ipynb        # NEW
â”‚   â”‚   â”œâ”€â”€ FT_swin_t_MCMLC.ipynb     # NEW
â”‚   â”‚   â””â”€â”€ Vision-Transformer-pytorch.ipynb  # NEW
â”‚   â”œâ”€â”€ Models/                       # Trained model checkpoints
â”‚   â”œâ”€â”€ Training-Statistics/          # CSV logs of training metrics
â”‚   â””â”€â”€ Training-Evolution-images/    # NEW - Training curves
â”‚
â”œâ”€â”€ data/                             # Dataset management
â”‚   â”œâ”€â”€ Training-Set/                 # Training images & labels
â”‚   â”œâ”€â”€ Test-Set/                     # Test images & labels
â”‚   â”œâ”€â”€ Evaluation-Set/               # Validation images & labels
â”‚   â”œâ”€â”€ source/                       # zip data from paper
â”‚   â””â”€â”€ mean-std/                     # Normalization statistics
â”‚
â”œâ”€â”€ tools/                            # Utility modules
â”‚   â”œâ”€â”€ data_tools.py                # Data loading & preprocessing
â”‚   â”œâ”€â”€ model_tools.py               # Model utilities
â”‚   â””â”€â”€ visualization_tools.py       # Plotting & visualization
â”‚
â””â”€â”€ EDA/                              # Exploratory Data Analysis
    â”œâ”€â”€ calculate_normalisation_statistics.py
    â””â”€â”€ DataSet_Analisys.ipynb

```

## ğŸ“– Usage

### Training a Model

Refer to the Jupyter notebooks in `model-training/Training-Notebooks/`:

1. **Simple CNN Binary Classification**:
   - Open `Simple_CNN_BC.ipynb`
   - Follow the notebook to train a custom CNN from scratch

2. **Fine-tuned Transfer Learning**:
   - Open `FT_ResNet50_MCMLC.ipynb` or `FT_DenseNet121_MCMLC.ipynb`
   - Learn how to fine-tune pre-trained models

### Data Exploration

Open `EDA/DataSet_Analisys.ipynb` to explore dataset statistics and distribution.

## ğŸ” Key Features

- **PyTorch Implementation**: Full PyTorch pipeline for training, validation, and testing
- **Transfer Learning**: Fine-tuning of pre-trained models (ResNet50, DenseNet121)
- **Data Augmentation**: Image preprocessing and normalization
- **Multi-scale Image Processing**: Support for different input sizes (256Ã—256, 516Ã—516, 1024Ã—1024)
- **Training Tracking**: CSV-based logging of training metrics and evolution
- **Modular Design**: Reusable classes for easy experimentation
- **Vision Transformer**: ViT architecture for advanced image understanding
- **Swin Transformer**: Fine-tuned Swin-T for efficient classification
- **Mixed Precision Training**: GPU optimization with torch.amp.GradScaler
- **Loss Balancing**: BCEWithLogitsLoss with class weight coefficients

## ğŸ“ˆ Current Status

- âœ… Data loading and preprocessing pipelines
- âœ… Multiple model architectures implemented (CNN, ResNet50, DenseNet121)
- âœ… Vision Transformer implementation completed
- âœ… Swin Transformer fine-tuning in progress
- ğŸ”„ **Currently**: Training and optimizing ViT and Swin-T models (256Ã—256 resolution)
- â³ Performance evaluation and benchmarking coming soon

## ğŸ¤– Hardware

Developed and tested on:
- **CPU**: AMD Ryzen 7 7800X3D
- **GPU**: NVIDIA RTX 5070 Ti
- **RAM**: 16GB+

## ğŸ“š Learning Resources

This project demonstrates:
- PyTorch fundamentals (tensors, autograd, nn.Module)
- Custom Dataset and DataLoader implementation
- Transfer learning and fine-tuning
- Model training loops with validation
- Checkpoint saving and loading
- GPU acceleration with CUDA

## ğŸ’¡ How to Use This Project

If you're learning PyTorch and computer vision:
1. Explore the model definitions in `classes/`
2. Study the training notebooks for implementation patterns
3. Modify and experiment with hyperparameters
4. Use the code as a foundation for your own projects

## ğŸ“„ Dataset Citation

If you use the RFMiD dataset, please cite:
- Pachade, R.R.; Porwal, P.; Kokil, P.; et al. Retinal Fundus Multi-Disease Image Dataset (RFMiD): A Dataset for Multi-Disease Classification of Retinal Fundus Images Using Conventional Machine Learning and Deep Learning. Data 2021, 6, 14. https://doi.org/10.3390/data6020014

## ğŸŒŸ Future Work

- Ensemble methods combining multiple architectures
- Explainability analysis (Grad-CAM, attention maps)
- Web interface for inference
- Performance benchmarking and optimization

## ğŸ‘¤ Author

Created as a portfolio project for roles in Machine Learning/AI and Bioinformatics.
LinkedIn : https://www.linkedin.com/in/luis-alexandre-alba-sanchez/ 

---

For questions or suggestions, feel free to open an issue or reach out!